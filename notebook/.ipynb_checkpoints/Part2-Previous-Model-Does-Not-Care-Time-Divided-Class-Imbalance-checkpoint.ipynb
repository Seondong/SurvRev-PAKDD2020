{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Previous model does not care class imbalanced from time division.\n",
    "\n",
    "Written by Sundong Kim (sundong.kim@kaist.ac.kr), Jan 14th, 2019,\n",
    "\n",
    "In this notebook, we introduce the description of our more realistic benchmark dataset.\n",
    "\n",
    "* First, we show the ineffectiveness of our old model.\n",
    "    * We first generate basic statistical features from each visit.\n",
    "        * total dwell time\n",
    "        * the number of area\n",
    "        * the number of unique areas\n",
    "    * Then we perform binary classification to predict customer revisit intention.\n",
    "* Second, we show how to deal with this issue by introducing time-related features, and show its drawbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# pre_release_path = '../data_sample/indoor/store_A/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this tutorial, we will use a store_A dataset.      # /data: 50,000 user dataset  /data_sample: 500 user sample dataset\n",
    "pre_release_path = '../data/indoor/store_A/'\n",
    "\n",
    "# Load dataset\n",
    "train_labels = pd.read_csv(pre_release_path+'train_labels.tsv', sep='\\t')\n",
    "test_labels = pd.read_csv(pre_release_path+'test_labels.tsv', sep='\\t')\n",
    "train_visits = pd.read_csv(pre_release_path+'train_visits.tsv', sep='\\t')\n",
    "test_visits = pd.read_csv(pre_release_path+'test_visits.tsv', sep='\\t')\n",
    "wifi_sessions = pd.read_csv(pre_release_path+'wifi_sessions.tsv', sep='\\t')\n",
    "\n",
    "wifi_sessions = wifi_sessions.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before feature engineering, querying some useful information from wifi-sessions data, and add to the dataframe.\n",
    "import time\n",
    "def add_infos(df):  \n",
    "    tst = time.time()\n",
    "    df['l_index'] = df['indices'].apply(lambda x: [int(y) for y in x.split(';')])\n",
    "    t1 = time.time()\n",
    "    print(t1-tst)\n",
    "    \n",
    "    newidx = [item for sublist in list(df.l_index) for item in sublist]\n",
    "    tmpdf = wifi_sessions.loc[newidx]\n",
    "    traj_lens = df.l_index.apply(len)\n",
    "\n",
    "    tmp_areas = list(tmpdf['area'])\n",
    "    tmp_dt = list(tmpdf['dwell_time'])\n",
    "    tmp_ts_end = list(np.array(tmpdf['ts'])+np.array(tmp_dt))  # end time\n",
    "    \n",
    "    rslt_dt = []\n",
    "    rslt_areas = []\n",
    "    rslt_ts_end = []\n",
    "    \n",
    "    i = 0\n",
    "    for x in traj_lens:\n",
    "        rslt_dt.append(tmp_dt[i:i+x])\n",
    "        rslt_areas.append(tmp_areas[i:i+x])\n",
    "        rslt_ts_end.append(max(tmp_ts_end[i:i+x]))\n",
    "        i += x\n",
    "        \n",
    "    df['dwell_times'] = rslt_dt\n",
    "    df['areas'] =  rslt_areas\n",
    "    df['ts_end'] = rslt_ts_end\n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(t2-t1)\n",
    "    return df \n",
    "    \n",
    "##### Very slow approach, so revised.    \n",
    "#     df['dwell_times'] = df['l_index'].apply(lambda x: [wifi_sessions.loc[idx]['dwell_time'] for idx in x])\n",
    "#     t2 = time.time()\n",
    "#     print(t2-t1)\n",
    "#     df['areas'] = df['l_index'].apply(lambda x: [wifi_sessions.loc[idx]['area'] for idx in x])\n",
    "#     t3 = time.time()\n",
    "#     print(t3-t2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16467881202697754\n",
      "0.6349506378173828\n",
      "0.08695721626281738\n",
      "0.31140756607055664\n"
     ]
    }
   ],
   "source": [
    "train_visits = add_infos(train_visits)\n",
    "test_visits = add_infos(test_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [824, 824, 780, 580, 173, 163, 163, 72, 89]\n",
       "1                [520, 520, 223, 8, 212, 74, 67]\n",
       "2                                  [351, 349, 8]\n",
       "Name: dwell_times, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_visits.dwell_times.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample code to generate features \n",
    "\n",
    "def statistical_feature_generator(x):\n",
    "    fs = []\n",
    "\n",
    "    total_dwell_time = sum(x['dwell_times'])   # total dwell time\n",
    "    num_area_trajectory_have = len(x['dwell_times'])  # the number of area\n",
    "    num_unique_area_sensed = len(set(x['areas']))  # the number of unique areas\n",
    "    \n",
    "    fs.append(total_dwell_time)\n",
    "    fs.append(num_area_trajectory_have)  \n",
    "    fs.append(num_unique_area_sensed)     \n",
    "    \n",
    "    return fs\n",
    "\n",
    "\n",
    "def add_statistical_features(train_visits):\n",
    "    df = train_visits.copy()\n",
    "    \n",
    "    features = df.apply(lambda x: statistical_feature_generator(x), axis=1)\n",
    "    featureName = ['total_dwell_time', 'num_area', 'num_unique_area']\n",
    "    \n",
    "    fdf = pd.DataFrame(list(np.asarray(features)), index=features.index, columns = featureName)\n",
    "    \n",
    "    # Combine feature values to the dataframe\n",
    "    df = pd.concat([df, fdf], axis=1)\n",
    "    del fdf\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visits = add_statistical_features(train_visits)\n",
    "test_visits = add_statistical_features(test_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visits['date_rel'] = train_visits['date']-min(train_visits.date)\n",
    "test_visits['date_rel'] = test_visits['date']-min(train_visits.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>wifi_id</th>\n",
       "      <th>date</th>\n",
       "      <th>indices</th>\n",
       "      <th>l_index</th>\n",
       "      <th>dwell_times</th>\n",
       "      <th>areas</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>num_area</th>\n",
       "      <th>num_unique_area</th>\n",
       "      <th>date_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v0</td>\n",
       "      <td>102</td>\n",
       "      <td>17176</td>\n",
       "      <td>50677;50678;50679;50684;50692;50693;50694;5069...</td>\n",
       "      <td>[50677, 50678, 50679, 50684, 50692, 50693, 506...</td>\n",
       "      <td>[824, 824, 780, 580, 173, 163, 163, 72, 89]</td>\n",
       "      <td>[in, 1f, 1f-e, 1f-f, b1, b1_only, b1-a, b1-b, ...</td>\n",
       "      <td>1484041483</td>\n",
       "      <td>3668</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1</td>\n",
       "      <td>102</td>\n",
       "      <td>17191</td>\n",
       "      <td>112666;112667;112670;112671;112672;112673;112679</td>\n",
       "      <td>[112666, 112667, 112670, 112671, 112672, 11267...</td>\n",
       "      <td>[520, 520, 223, 8, 212, 74, 67]</td>\n",
       "      <td>[in, 1f, b1, cafe, b1_only, b1-a, b1-b]</td>\n",
       "      <td>1485343191</td>\n",
       "      <td>1624</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v2</td>\n",
       "      <td>102</td>\n",
       "      <td>17199</td>\n",
       "      <td>149230;149231;149254</td>\n",
       "      <td>[149230, 149231, 149254]</td>\n",
       "      <td>[351, 349, 8]</td>\n",
       "      <td>[in, 1f, 1f-e]</td>\n",
       "      <td>1486033703</td>\n",
       "      <td>708</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visit_id  wifi_id   date                                            indices  \\\n",
       "0       v0      102  17176  50677;50678;50679;50684;50692;50693;50694;5069...   \n",
       "1       v1      102  17191   112666;112667;112670;112671;112672;112673;112679   \n",
       "2       v2      102  17199                               149230;149231;149254   \n",
       "\n",
       "                                             l_index  \\\n",
       "0  [50677, 50678, 50679, 50684, 50692, 50693, 506...   \n",
       "1  [112666, 112667, 112670, 112671, 112672, 11267...   \n",
       "2                           [149230, 149231, 149254]   \n",
       "\n",
       "                                   dwell_times  \\\n",
       "0  [824, 824, 780, 580, 173, 163, 163, 72, 89]   \n",
       "1              [520, 520, 223, 8, 212, 74, 67]   \n",
       "2                                [351, 349, 8]   \n",
       "\n",
       "                                               areas      ts_end  \\\n",
       "0  [in, 1f, 1f-e, 1f-f, b1, b1_only, b1-a, b1-b, ...  1484041483   \n",
       "1            [in, 1f, b1, cafe, b1_only, b1-a, b1-b]  1485343191   \n",
       "2                                     [in, 1f, 1f-e]  1486033703   \n",
       "\n",
       "   total_dwell_time  num_area  num_unique_area  date_rel  \n",
       "0              3668         9                9         9  \n",
       "1              1624         7                7        24  \n",
       "2               708         3                3        32  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_visits.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Revisit Prediction (Binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "def show_intention_classification_result(y_pred, y_test):\n",
    "    return metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "def show_interval_regression_result(y_pred, y_test):\n",
    "    return metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling for measuring binary classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([train_visits, train_labels[['revisit_intention','revisit_interval']]], axis=1)\n",
    "df_test = pd.concat([test_visits, test_labels[['revisit_intention','revisit_interval']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate 'suppress_time' column for evaluation\n",
    "def generate_suppress_time_col(df):\n",
    "    last_ts_end = max(df['ts_end'])\n",
    "    df['tmp_suppress_time'] = [(last_ts_end-x)/86400 for x in df['ts_end']]\n",
    "    df['suppress_time'] = np.maximum(df['revisit_interval'].fillna(0), df['revisit_interval'].isnull()*df['tmp_suppress_time'])\n",
    "    del df['tmp_suppress_time']\n",
    "    return df\n",
    "    \n",
    "df_train = generate_suppress_time_col(df_train)\n",
    "df_test = generate_suppress_time_col(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retain only feature values\n",
    "\n",
    "def remove_unnecessary_features(df):\n",
    "    unnecessary_attributes = ['visit_id', 'indices', 'l_index', 'dwell_times', 'areas', 'ts_end'] #'wifi_id', \n",
    "    all_attributes = list(df.columns)\n",
    "    for attribute in unnecessary_attributes:\n",
    "        try:\n",
    "            all_attributes.remove(attribute)\n",
    "        except:\n",
    "            pass\n",
    "    df = df[all_attributes]\n",
    "    return df\n",
    "\n",
    "df_train = remove_unnecessary_features(df_train)\n",
    "df_test = remove_unnecessary_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_balancing(df, name_target_column):\n",
    "    ## No downsampling\n",
    "    return df\n",
    "    \n",
    "#     ## 1:1 Downsampling\n",
    "#     minimum_label_num = list(df[name_target_column].value_counts())[-1]\n",
    "    \n",
    "#     df_list = []\n",
    "#     for value in df[name_target_column].unique():\n",
    "#         sub_dfs = df.loc[df[name_target_column] == value]\n",
    "#         new_sub_dfs = sub_dfs.iloc[np.random.permutation(len(sub_dfs))][:minimum_label_num]  ## Random Downsampling according to smallest label size\n",
    "#         df_list.append(new_sub_dfs)\n",
    "#         del sub_dfs\n",
    "        \n",
    "#     new_df = pd.concat(df_list).sort_index()\n",
    "    \n",
    "#     return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wifi_id</th>\n",
       "      <th>date</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>num_area</th>\n",
       "      <th>num_unique_area</th>\n",
       "      <th>date_rel</th>\n",
       "      <th>revisit_intention</th>\n",
       "      <th>revisit_interval</th>\n",
       "      <th>suppress_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>17176</td>\n",
       "      <td>3668</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15.06</td>\n",
       "      <td>15.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>17191</td>\n",
       "      <td>1624</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>7.99</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>17199</td>\n",
       "      <td>708</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>13.96</td>\n",
       "      <td>13.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wifi_id   date  total_dwell_time  num_area  num_unique_area  date_rel  \\\n",
       "0      102  17176              3668         9                9         9   \n",
       "1      102  17191              1624         7                7        24   \n",
       "2      102  17199               708         3                3        32   \n",
       "\n",
       "   revisit_intention  revisit_interval  suppress_time  \n",
       "0                  1             15.06          15.06  \n",
       "1                  1              7.99           7.99  \n",
       "2                  1             13.96          13.96  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5798116566716642, 0.7572577131767595)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sum(df_train.revisit_intention)/len(df_train.revisit_intention), 1-sum(df_test.revisit_intention)/len(df_test.revisit_intention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    137.344502\n",
       "1      8.020000\n",
       "2      0.710000\n",
       "3    137.344722\n",
       "4    176.123993\n",
       "Name: suppress_time, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['suppress_time'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------   Experiments Begin   -------------\n",
      "\n",
      "Class label distribution after downsampling - Train data: revisit_intention 0: 24751, 1: 17937\n",
      "Class label distribution after downsampling - Test data: revisit_intention 0: 19120, 1: 6129\n",
      "\n",
      "-----------   Performance of our model   -------------\n",
      "\n",
      "Option: no_date\n",
      "Average elapsed_time (with XGBClassif): 2.0605\n",
      "Average accuracy (with XGBClassif): 0.7547\n",
      "Average precision_macro (with XGBClassif): 0.7291\n",
      "Average recall_macro (with XGBClassif): 0.8079\n",
      "Average fscore_macro (with XGBClassif): 0.7282\n",
      "Average elapsed_time (with XGBRegress): 2.4801\n",
      "Average MSE (with XGBRegress): 3579.2952\n",
      "Average cindex (with XGBRegress): 0.6967\n",
      "\n",
      "Option: date\n",
      "Average elapsed_time (with XGBClassif): 2.5840\n",
      "Average accuracy (with XGBClassif): 0.7683\n",
      "Average precision_macro (with XGBClassif): 0.7112\n",
      "Average recall_macro (with XGBClassif): 0.7627\n",
      "Average fscore_macro (with XGBClassif): 0.7233\n",
      "Average elapsed_time (with XGBRegress): 2.8801\n",
      "Average MSE (with XGBRegress): 1955.7829\n",
      "Average cindex (with XGBRegress): 0.2234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lifelines\n",
    "\n",
    "print('-----------   Experiments Begin   -------------')\n",
    "print()\n",
    "\n",
    "clfs = [Pipeline([('classification', XGBClassifier(max_depth=5, learning_rate=0.1))]), \n",
    "                Pipeline([('regression', XGBRegressor(max_depth=5, learning_rate=0.1))]),\n",
    "               ]\n",
    "\n",
    "options = ['no_date', 'date']\n",
    "\n",
    "rslt = {}\n",
    "for opt in options:\n",
    "    rslt[opt] = {}\n",
    "    for clf in clfs:\n",
    "        rslt[opt][clf] = {}\n",
    "        rslt[opt][clf]['elapsed_time'] = []\n",
    "        for metric in ['accuracy', 'precision_macro', 'recall_macro', 'fscore_macro', 'MSE', 'cindex']:\n",
    "            rslt[opt][clf][metric] = []\n",
    "\n",
    "\n",
    "## 나중에 더 정교화 (실제 cut-off point 가지고)\n",
    "train_date_max = max(df_train.date)\n",
    "test_date_max = max(df_test.date)\n",
    "    \n",
    "for i in range(2):\n",
    "    for opt in ['no_date', 'date']:\n",
    "        ## Making downsampled dataset for measuring binary classification accuracy - baseline = 0.5\n",
    "        if opt == 'no_date':\n",
    "            whole_balanced_train = label_balancing(df_train, 'revisit_intention')[df_train.columns.drop(['date','date_rel'])]\n",
    "            whole_balanced_test = label_balancing(df_test, 'revisit_intention')[df_train.columns.drop(['date','date_rel'])]   \n",
    "            \n",
    "        if opt == 'date':\n",
    "            whole_balanced_train = label_balancing(df_train, 'revisit_intention') \n",
    "            whole_balanced_test = label_balancing(df_test, 'revisit_intention')\n",
    "    \n",
    "        if (i == 0) and (opt == 'no_date'):\n",
    "            print('Class label distribution after downsampling - Train data: revisit_intention 0: {}, 1: {}'.format(\n",
    "                whole_balanced_train.revisit_intention.value_counts()[0],\n",
    "                whole_balanced_train.revisit_intention.value_counts()[1]))\n",
    "            print('Class label distribution after downsampling - Test data: revisit_intention 0: {}, 1: {}'.format(\n",
    "                whole_balanced_test.revisit_intention.value_counts()[0],\n",
    "                whole_balanced_test.revisit_intention.value_counts()[1]))\n",
    "\n",
    "\n",
    "        for (train_data, test_data, ref) in [(whole_balanced_train, whole_balanced_test, 'Downsampled')]:\n",
    "            train_array = np.asarray(train_data)  \n",
    "            test_array = np.asarray(test_data)  \n",
    "\n",
    "            for clf in clfs:\n",
    "                if clf.steps[0][0] == 'classification':\n",
    "\n",
    "                    # Dividing features and labels\n",
    "                    X_train, y_train = train_array[:, :-3], train_array[:, -3].astype(int)\n",
    "                    X_test, y_test = test_array[:, :-3], test_array[:, -3].astype(int)\n",
    "\n",
    "                    # Training\n",
    "                    start = time.time()\n",
    "                    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "                    # Prediction\n",
    "                    y_pred = clf.predict(X_test)\n",
    "\n",
    "                    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "                    pm,rm,fm,_ = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "                    rslt[opt][clf]['accuracy'].append(acc)\n",
    "                    rslt[opt][clf]['precision_macro'].append(pm)\n",
    "                    rslt[opt][clf]['recall_macro'].append(rm)\n",
    "                    rslt[opt][clf]['fscore_macro'].append(fm)\n",
    "\n",
    "                else:\n",
    "                    # Dividing features and labels\n",
    "                    X_train, y_train = train_array[:, :-3], train_array[:, -1]\n",
    "                    X_test, y_test = test_array[:, :-3], test_array[:, -1]\n",
    "                    y_test_bin = test_array[:,-3]\n",
    "                    \n",
    "\n",
    "                    # Training\n",
    "                    start = time.time()\n",
    "                    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "                    # Prediction\n",
    "                    y_pred = clf.predict(X_test)\n",
    "#                     mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "\n",
    "#                     y_test_max = max(y_test)\n",
    "                    mse = metrics.mean_squared_error(y_test[y_test_bin == 1], y_pred[y_test_bin == 1])\n",
    "                    \n",
    "                    cindex = lifelines.utils.concordance_index(y_test, y_pred, event_observed= y_test_bin == 1)\n",
    "\n",
    "                    rslt[opt][clf]['MSE'].append(mse)\n",
    "                    rslt[opt][clf]['cindex'].append(cindex)\n",
    "\n",
    "\n",
    "                done = time.time()\n",
    "                elapsed = done-start\n",
    "                rslt[opt][clf]['elapsed_time'].append(elapsed)\n",
    "                \n",
    "                if opt == 'no_date':\n",
    "                    no_date_pred = y_pred\n",
    "                    no_date_test = y_test\n",
    "                if opt == 'date':\n",
    "                    date_pred = y_pred\n",
    "                    date_test = y_test\n",
    "                    \n",
    "                \n",
    "                \n",
    "\n",
    "print()\n",
    "print('-----------   Performance of our model   -------------')\n",
    "print()\n",
    "\n",
    "    \n",
    "for opt in options:\n",
    "    print('Option: {}'.format(opt))\n",
    "    for clf in clfs:\n",
    "        for key in rslt[opt][clf].keys():\n",
    "            if len(rslt[opt][clf][key]) > 0:\n",
    "                print('Average {} (with {}): {:.4f}'.format(key, str(clf.steps[0][1])[:10], np.mean(rslt[opt][clf][key])))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.04306507,   8.14346123, 137.34450231,   0.        ],\n",
       "       [ 24.09877014,  14.48282242,   8.02      ,   1.        ],\n",
       "       [ 34.82921982,  16.55454254,   0.71      ,   1.        ],\n",
       "       [ 56.15962982,  31.70885277, 137.34472222,   0.        ],\n",
       "       [ 48.0329895 ,  28.5895195 , 176.12399306,   0.        ],\n",
       "       [ 31.69169807,  20.8321209 ,  24.04872685,   0.        ],\n",
       "       [ 28.38632393,   6.34554625,  26.06      ,   1.        ],\n",
       "       [ 25.93292809,  17.68218803,  10.92      ,   1.        ],\n",
       "       [ 19.6152401 ,  18.82816315,   1.19      ,   1.        ],\n",
       "       [ 31.8152771 ,  16.68383217, 108.09      ,   1.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([no_date_pred, date_pred, date_test, y_test_bin]).T[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6756756756756757\n",
      "0.6216216216216216\n"
     ]
    }
   ],
   "source": [
    "### no_date_pred의 sample 데이터의 concordance index\n",
    "print(lifelines.utils.concordance_index(date_test[:10], no_date_pred[:10], event_observed= y_test_bin[:10] == 1))\n",
    "### date_pred의 sample 데이터의 concordance index\n",
    "print(lifelines.utils.concordance_index(date_test[:10], date_pred[:10], event_observed= y_test_bin[:10] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wifi_id</th>\n",
       "      <th>date</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>num_area</th>\n",
       "      <th>num_unique_area</th>\n",
       "      <th>date_rel</th>\n",
       "      <th>revisit_intention</th>\n",
       "      <th>revisit_interval</th>\n",
       "      <th>suppress_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42685</th>\n",
       "      <td>99995</td>\n",
       "      <td>17190</td>\n",
       "      <td>5922</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.257627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42686</th>\n",
       "      <td>99996</td>\n",
       "      <td>17236</td>\n",
       "      <td>4601</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.211296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42687</th>\n",
       "      <td>99999</td>\n",
       "      <td>17250</td>\n",
       "      <td>1294</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.223218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wifi_id   date  total_dwell_time  num_area  num_unique_area  date_rel  \\\n",
       "42685    99995  17190              5922         9                9        23   \n",
       "42686    99996  17236              4601         9                9        69   \n",
       "42687    99999  17250              1294         8                8        83   \n",
       "\n",
       "       revisit_intention  revisit_interval  suppress_time  \n",
       "42685                  0               NaN     157.257627  \n",
       "42686                  0               NaN     111.211296  \n",
       "42687                  0               NaN      97.223218  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_balanced_train.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-a175eb6c4775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# `event_col` refers to whether the 'death' events was observed: 1 if observed, 0 else (censored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m cph.fit(whole_balanced_train[whole_balanced_train.columns.drop(['revisit_interval'])], \n\u001b[0;32m----> 7\u001b[0;31m         'suppress_time', event_col='revisit_intention', show_progress=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mcph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmlab/ksedm1/anaconda3/envs/py36/lib/python3.6/site-packages/lifelines/fitters/coxph_fitter.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, duration_col, event_col, show_progress, initial_beta, strata, step_size, weights_col)\u001b[0m\n\u001b[1;32m    141\u001b[0m                                          \u001b[0minitial_beta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_beta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                                          \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                                          step_size=step_size)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhazards_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhazards_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_norm_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmlab/ksedm1/anaconda3/envs/py36/lib/python3.6/site-packages/lifelines/fitters/coxph_fitter.py\u001b[0m in \u001b[0;36m_newton_rhaphson\u001b[0;34m(self, X, T, E, weights, initial_beta, step_size, precision, show_progress, max_steps)\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 raise ValueError(\"\"\"delta contains nan value(s). Convergence halted. Please see the following tips in the lifelines documentation:\n",
      "\u001b[0;32m/home/dmlab/ksedm1/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dmlab/ksedm1/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "\n",
    "# Using Cox Proportional Hazards model\n",
    "cph = CoxPHFitter()\n",
    "# `event_col` refers to whether the 'death' events was observed: 1 if observed, 0 else (censored)\n",
    "cph.fit(whole_balanced_train[whole_balanced_train.columns.drop(['revisit_interval'])], \n",
    "        'suppress_time', event_col='revisit_intention', show_progress=False)\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = cph.predict_expectation(whole_balanced_test[whole_balanced_test.columns.drop(['revisit_interval','revisit_intention','suppress_time'])])\n",
    "score_test = lifelines.utils.concordance_index(whole_balanced_test['suppress_time'], test_pred[0], event_observed=whole_balanced_test['revisit_intention'])\n",
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = cph.predict_median(whole_balanced_test[whole_balanced_test.columns.drop(['revisit_interval','revisit_intention','suppress_time'])])\n",
    "score_test = lifelines.utils.concordance_index(whole_balanced_test['suppress_time'], test_pred[0.5], event_observed=whole_balanced_test['revisit_intention'])\n",
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([whole_balanced_test['suppress_time'], test_pred[0.5], whole_balanced_test['revisit_intention']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## C-index test\n",
    "\n",
    "lifelines.utils.concordance_index(np.array([1,2,3,4,5,6,7]), np.array([4,2,3,5,1,6,7]), event_observed=np.array([1,0,1,0,1,0,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
